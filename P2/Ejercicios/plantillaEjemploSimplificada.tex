\input{preambuloSimple.tex}

%----------------------------------------------------------------------------------------
%	TÍTULO Y DATOS DEL ALUMNO
%----------------------------------------------------------------------------------------

\title{
\normalfont \normalsize
\texttt{{\bf Visión Por Computador (2015-2016)} \\ Grado en Ingeniería Informática \\ Universidad de Granada} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Informe Trabajo 2 - Estimación de Homografías y Construcción de panoramas \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Mª Cristina Heredia Gómez} % Nombre y apellidos

\date{\normalsize\today} % Incluye la fecha actual

%----------------------------------------------------------------------------------------
% DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Muestra el Título

\newpage %inserta un salto de página

\tableofcontents % para generar el índice de contenidos

\listoffigures

%\listoftables

\newpage

%NOTA: en caso de problema al compilar, compruebe que tiene el paquete: texlive-babel-spanish.noarch  \\


\newpage

%----------------------------------------------------------------------------------------
%	Ejercicio1
%----------------------------------------------------------------------------------------
\section{Estimación de una homografía: Usar las imagenes tablero1 y tablero2
incluidas en el fichero de datos para estimar la homografía que relaciona
ambas imagenes. (2.5 puntos) \newline
Para ello realizar lo siguiente: \newline
1.- Seleccionar a mano un conjunto de 10 puntos en correspondencias
en ambas imagenes (distribuir dichos puntos de la forma más uniforme posible
entre los puntos esquina del tablero). \newline
2.- Estimar la homografía (implementar código propio, SIN usar
findHomography()) definida entre las imagenes por las parejas de puntos
seleccionados \newline
3.-Usar la función warpPerspective() para generar a partir de una de las
imagenes y la homografía estimada, la otra imagen. Comentar el resultado
obtenido en comparación con la imagen original. \newline
4.- Repetir los puntos anteriores pero seleccionando nuevos 10 puntos,
en este caso todos extraídos de 3 cuadrados contiguos de una misma esquina.
Comparar el resultado obtenidos con el anterior y valorar las diferencias
encontradas.}

Tenemos:
\[\begin{pmatrix} u\\ v\\ w \end{pmatrix}=H\begin{pmatrix} x\\ y\\ 1 \end{pmatrix}\Rightarrow \begin{pmatrix} u\\ v\\ w \end{pmatrix}=\begin{pmatrix} h_{1}x& +h_{2}y &+h_{3} \\ h_{4}x& +h_{5}y &+h_{6} \\ h_{7}x& +h_{8}y & +h_{9} \end{pmatrix}\]
donde \[ X=\begin{pmatrix} x\\ y\\ 1 \end{pmatrix} \] y sabemos que $u=\frac{x1}{x3}$ y que $u=\frac{x2}{x3}$ ,donde $x1$ es la fila 1 de Xh. Luego tenemos que:
\[u=\frac{h_{1}x+h_{2}y+h_{3}}{h_{7}x+h_{8}y+h_{9}}\]
$\Rightarrow$ \[u(h_{7}x+h_{8}y+h_{9})-(h_{1}x+h_{2}y+h_{3})=0\]
y análogamente:
\[v=\frac{h_{4}x+h_{5}y+h_{6}}{h_{7}x+h_{8}y+h_{9}}\]
$\Rightarrow$ \[v(h_{7}x+h_{8}y+h_{9})-h_{4}x-h_{5}y-h_{6}=0\]
que escribiéndolo matricialmente, queda como:
\[A_{i}=\bigl(\begin{smallmatrix} -x&-y &-1 &0 &0 &0 &ux &uy &u \\ 0& 0& 0&-x &-y &-1 &vx &vy &v \end{smallmatrix}\bigr)\]
y si juntamos cada $A_{i}$ obtenemos A ,tal que $ A \cdot h=0$ donde \[h=\begin{pmatrix} h_{1} &h_{2} & h_{3} &h_{4} &h_{5} &h_{6} &h_{7} &h_{8} &h_{9} \end{pmatrix}^{T}\]

Pues bien, la idea para implementar el algoritmo que estima la homografía no ha sido más que esta. Calculamos
lo que sería la matriz A, que tendrá tantas filas como número de puntos por dos, ya que por cada punto se añaden dos filas,
y tendrá 9 columnas. \newline
Para ello, mi función recibe la imagen original y dos vectores de puntos. Un vector pertenece a la imagen original y el otro son puntos
de la imagen que queremos estimar. \newline
 Luego, con un bucle sencillo vamos calculando para cada pareja de puntos, sus dos filas de $A_{i}$. Finalmente, cuando
ya tenemos A completa, descomponemos en valores singulares la matriz A,llamando a la función \textbf{SVD} de OpenCV que hace justo eso,
y paśandole la opción \textbf{MODIFY\_A} para que modifique A directamente y así ahorrarnos hacer una copia. \newline
Hecho todo esto ya sólo hay que tomar el autovalor que hay en la posición 8, pues como sabemos
la 8 es la posición última y ahí es donde se encuentra el valor mínimo. \newline
Inicialmente, tomamos 10 puntos distribidos por el tablero. Yo lo he hecho en el main y he usado la stl para ello:
\myCppCode{CV_Practica2/main}{main}{21}{48}
Una vez que tenemos los puntos, solo queda estimar la homografía y aplicar la transformación de perspectiva a la imagen 1.
Para estimar la homografía, he implementado la siguiente función:
\myCppCode{CV_Practica2/funciones}{funciones}{30}{76}
y vemos en el resultado que nos calcula una homografía con algunos bordes negros, pero por lo general, bastante similar al Tablero2, a partir
del tablero1:
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.37]{hcalculada.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{Tablero1 y homografía calculada  }
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.3]{Tablero2.jpg}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{imagen Tablero2.jpg original}
\end{figure}

Si experimentamos ahora tomando los 10 puntos en 3 cuadrados contiguos de una misma esquina (puntos declarados en el main), obtenemos
el siguiente resultado:
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.3]{homo4c.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{homografia calculada tomando 10 puntos en cuadrados consecutivos del tablero }
\end{figure}
y vemos que, estimar la homografía la estima, pero bastante más amorfa que si distribuimos los puntos por la imagen en lugar
de centrarnos solo en una zona.

%----------------------------------------------------------------------------------------
%	Ejercicio2
%----------------------------------------------------------------------------------------
\section{Usar los detectores SIFT y SURF de OpenCV sobre las imagenes de
Yosemite para extraer y pintar sobre las mismas las regiones relevantes
encontradas por los mismos (mirar el contenido de la estructura keyPoint
asociada a cada punto detectado). Comenzar usando los parámetros por
defecto de los constructores de SIFT y SURF e ir modificando los umbrales de
detección hasta que obtengamos resultados razonables). Comparar los
resultados obtenidos por ambos detectores y justificar los parámetros usados
(1.5 punto)}
En lugar de SIFT Y SURF hemos usado los detectores BRISK Y ORB. Para aplicar estos detectores sobre las
imagenes, he programado una función por cada detector, una llamada: \textbf{aplicaBRISK}, y otra que se llama
\textbf{aplicaORB}. Ambas reciben como parámetros \textbf{una imagen} sobre la que aplicar el detector,
\textbf{un vector de keypoints} vacío, \textbf{un descriptor} vacío y \textbf{una matriz de salida} que
contendrá el resultado de haber aplicado el detector.\newline

\myCppCode{CV_Practica2/funciones}{funciones}{76}{91}
Como vemos, el procedimiento es sencillo. Creamos un detector BRISK paśandole los parámetros deseados,
llamamos a la función \textbf{detect} pasándole la foto y el vector de keypoints vacío, y esta función detectará los puntos clave
y nos devolverá nuestro vector de keypoints relleno, luego llamamos a \textbf{compute} que nos devolverá el descriptor relleno y
por último, se llama a \textbf{drawKeypoints} que pinta los puntosclave en la imagen. \newline
En cuanto a los parámetros, tomé \textbf{thresh} =65 ,porque me di cuenta haciendo pruebas que con ese umbral de detección
detectaba algunos puntos que con umbrales inferiores o superiores(80 por ej) no. las \textbf{octaves} las puse a 5 , aunque por defecto venían a 3 y no varían mucho el resultado.
Finalmente, puse \textbf{patternScale} a 1.5f para que se aplicara una escala un poco más grande que la que venía por defecto
al muestrear el vecindario de un punto. \newline
\newline
En cuanto a ORB, el procedimiento es similar al de BRISK, pero creándonos un detector ORB. Para ORB he elegido los parámetros:
\textbf{nfeatures}  750 en lugar de 500 como venía por defecto, para que retenga más muestras, el \textbf{scaleFactor} lo he subido a 1.3f partial 1.2f que viene por defecto
\textbf{nlevels} lo he subido de 8 a 9 , para que la pirámide tuviera un nivel más. También puse \textbf{WTA\_K} a 3, para
que el número de puntos que produzca cada elemento se calcule a partir de 3 puntos. El resto de parámetros, se mantienen como vienen por defecto.

\myCppCode{CV_Practica2/funciones}{funciones}{93}{113}

Resultados de ejecución:
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.36]{brisk.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{resultado ejecución detector BRISK sobre yosemite1 y yosemite2}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.37]{orb.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{resultado ejecución detector ORB sobre yosemite1 y yosemite2}
\end{figure}
%----------------------------------------------------------------------------------------
%	Ejercicio3
%----------------------------------------------------------------------------------------
\section{Con los resultados de detección obtenidos en el punto anterior extraer el
descriptor asociado a cada punto y establecer la lista de puntos en
correspondencias existentes en las imagenes ( Ayuda: usar la claseDescriptorMatcher y BFMatcher). Valorar la calidad de los resultados obtenidos
bajo los criterios BruteForce+crossCheck y FlannBasedMatcher(). (1 punto)}
Para este ejercicio me he implementado una función con nombre \textbf{hallaCorrep} que tiene como objetivo detectar las coincidencias
entre los keypoint de una imagen y los de otra. La función, recibe dos imagenes, dos listas reviament rellenas de keypoints , dos descriptores
previamente rellenos , el criterio a utilizar para hacer el matching y un vector de coincidencias vacío que se rellenará
dentro de la función. \newline
En esta función, se comprueba el criterio elegido (establecido en el main). Si el criterio es \textbf{BFCrossCheck} entonces
emparejamos por fuerza bruta más crosscheck. Para ello, nos definimos un BFMatcher , y como usamos BRISK  y ORB para calcular
descriptores y keypoints, le pasamos la opción \textbf{NORM\_HAMMING} y el \textbf{crosscheck} a true. \newline
Sin embargo, si el criterio seleccionado en el main es \textbf{Flann}, nos declaramos un matcher basado en flann, especificando
el algoritmo de esta librería que queremos usar. En este caso, yo uso \textbf{LshIndexParams} porque, después de probar con muchos
es el que mejor funciona. (probé a hacerlo con DescriptorMatcher pero daba fallo.) \newline
Finalmente, para cualquiera de ambos criterios, hacemos el match llamando al método \textbf{match} que nos rellena el vector
de coincidencias y una vez que lo tenemos relleno, pintamos las coincidencias con \textbf{drawMatches}.
\myCppCode{CV_Practica2/funciones}{funciones}{113}{143}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.37]{orbFLANN.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{coincidencias calculadas usando detector ORB y FLANNbased matcher sobre yosemite1 y yosemite2}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.37]{briskFLANN.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{coincidencias calculadas usando detector BRISK y FLANNbased matcher sobre yosemite1 y yosemite2}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.37]{orbBF.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{coincidencias calculadas usando detector ORB y BRUTEFORCEbased matcher sobre yosemite1 y yosemite2}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.37]{briskBF.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{coincidencias calculadas usando detector BRISK y BRUTEFORCEbased matcher sobre yosemite1 y yosemite2}
\end{figure}

\section{Escribir una función que tome como entrada dos imagenes relacionadas por
una homografía, sus listas de keyPoints en correspondencia calculados de
acuerdo al punto anterior y estime la homografía entre ellas usando el criterio
RANSAC con la función findHomography(p1,p2, CV\_RANSAC,1 ). Crear un
mosaico con ambas imagenes. ( Ayuda: Para el mosaico será necesario. a)
definir una imagen en la que pintaremos el mosaico; b) definir la homografía
que lleva cada una de las imagenes a la imagen del mosaico; c) usar la función
warpPerspective() para trasladar cada imagen al mosaico (ayuda: usar
borderMode=BORDER\_TRANSPARENT )). (2 puntos)}
Llegados aquí ya está casi todo hecho. Puesto que la función \textbf{findHomography} recibe dos vectores
de puntos \textbf{Point2f}, es preciso obtener dichos Point2f a partir del vector de DMatch recibido y los vectores
de keypoints que le hemos pasado. Para ello, para cada una de las coincidencias buscamos el keypoints1 que se
corresponde, y el keypoints2 con el que se corresponde y los vamos metiendo en su respectivo vector de Point2f. \newline
luego, nos declaramos H1 como:
\[H1=\begin{pmatrix} 1& 0 &c_{x} \\ 0& 1& c_{y}\\ 0& 0& 1 \end{pmatrix}\]
y llevaremos la primera imagen al mosaico mediante H1, usando \textbf{warpPersective}. (Previamente habrá sido necesario definir
un tamaño para el mosaico). Luego, calculamos H2, que será la homografía que pasa de la imagen 1 a la 2, a través
de vectores de puntos de ambas imagenes ya conocidos. \newline
Por último, componemos las homografías multiplicando la 1 por la 2, obteniendo así una nueva homografía que será mediante la cual
pegaremos la imagen 2 en el mosaico.
\myCppCode{CV_Practica2/funciones}{funciones}{143}{180}
\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
\centering
\includegraphics[scale=0.55]{mosaico.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
\label{figura1}
\caption{mosaico hecho con las imágenes mosaico002 y mosaico003}
\end{figure}

%------------------------------------------------
%\bibliography{citas} %archivo citas.bib que contiene las entradas
%\bibliographystyle{plain} % hay varias formas de citar

%\chapter*{Bibliograf\'ia}
%\section*{Referencias}
%\addcontentsline{toc}{section}{Articles}
%\printbibliography[heading=bibempty,type=article]
%\printbibliography[heading=bibempty,type=misc]
\end{document}
